# PhaseGPT v1.5 Integration Guide

## Overview

PhaseGPT v1.5 enhances the core `<PASS>` mechanism with:
1. **VolitionalMetrics** - Agency Cliff monitoring
2. **PassLogitBias** - Runtime refusal control
3. **KnownnessHead** - Learned entity familiarity
4. **PassAttribution** - Explainable refusal (Phase 4)

All enhancements are **opt-in** and **backward compatible** with v1.4.

---

## Quick Start

### 1. Add Metrics to Training Loop

```python
# In your training script (e.g., scripts/train_production.py)
from phasegpt.metrics.volition_metrics import VolitionalMetrics

# After model/tokenizer setup
pass_token_id = tokenizer.convert_tokens_to_ids("<PASS>")
volition_metrics = VolitionalMetrics(pass_token_id)

# In evaluation loop (after each epoch)
# Collect predictions and corruption flags
pred_token_ids = []  # First generated token for each sample
corruption_flags = []  # From your corruption engine

for batch in eval_dataloader:
    outputs = model.generate(batch['input_ids'], max_new_tokens=1)
    pred_token_ids.extend(outputs[:, -1].cpu().tolist())
    corruption_flags.extend(batch['is_corrupted'].cpu().tolist())

# Compute metrics
report = volition_metrics.compute(pred_token_ids, corruption_flags)

print(f"[Epoch {epoch}] {report.status}")
print(f"  PassRate(valid):   {report.pass_rate_valid:.2%}")
print(f"  PassRate(corrupt): {report.pass_rate_corrupted:.2%}")
print(f"  Safety Margin:     {report.safety_margin:.2%}")

# Alert on collapse
if "SYCOPHANT" in report.status or "SLOTH" in report.status:
    print(f"⚠️  WARNING: Agency Cliff degradation detected!")
```

### 2. Add Tunable Bias to Inference

```python
# In your chat/generation script (e.g., scripts/chat_phase_oracle_qwen.py)
from phasegpt.generation.pass_logit_bias import create_pass_bias_processor

# Add CLI argument
parser.add_argument('--pass-bias', type=float, default=0.0,
                    help='<PASS> logit bias: >0 more cautious, <0 less cautious')
args = parser.parse_args()

# Create processor
pass_bias_processor = create_pass_bias_processor(
    tokenizer=tokenizer,
    bias=args.pass_bias,
    adaptive=False  # Set True for entropy-based adaptation
)

# Use in generation
response = generate_text(
    model=model,
    tokenizer=tokenizer,
    prompt=user_prompt,
    logits_processor=[pass_bias_processor],  # ← Add this
    temperature=temperature,
    max_tokens=max_tokens
)
```

**Command line usage:**
```bash
# Default behavior (bias=0.0)
python scripts/chat_phase_oracle_qwen.py

# More cautious (higher refusal rate)
python scripts/chat_phase_oracle_qwen.py --pass-bias 0.5

# Less cautious (lower refusal rate)
python scripts/chat_phase_oracle_qwen.py --pass-bias -0.5
```

### 3. Add KnownnessHead to Training

**Step 1: Update architecture config**

```yaml
# config/architecture_config.yaml

# Existing volition config
volitional_head_dim: 128

# NEW: Knownness head configuration
use_knownness_head: true
knownness_head_dim: 64
knownness_layer_idx: 12  # Which layer to extract features from
knownness_loss_weight: 0.1
```

**Step 2: Modify VolitionalTrainer**

```python
# In src/phasegpt/trainer/volitional.py

from phasegpt.modules.knownness_head import KnownnessHead

class VolitionalTrainer:
    def __init__(self, model, tokenizer, arch_config, ...):
        # ... existing setup ...

        # NEW: Initialize KnownnessHead if enabled
        if arch_config.use_knownness_head:
            hidden_dim = model.config.hidden_size
            self.knownness_head = KnownnessHead(
                hidden_dim=hidden_dim,
                head_dim=arch_config.knownness_head_dim
            ).to(self.device)
            print(f"[VolitionalTrainer] KnownnessHead enabled (layer {arch_config.knownness_layer_idx})")
        else:
            self.knownness_head = None

    def train(self, train_dataset, num_epochs=3):
        # ... existing training loop ...

        # In forward pass (inside batch loop):
        if self.knownness_head is not None:
            # Forward with hidden states
            outputs = self.model(
                **batch,
                output_hidden_states=True  # ← Enable this
            )

            # Extract mid-layer features
            layer_idx = self.arch_config.knownness_layer_idx
            hidden_states = outputs.hidden_states[layer_idx]
            pooled = hidden_states[:, -1, :]  # Last token position

            # Compute knownness loss
            is_answerable = ~batch['is_corrupted']  # True = answerable
            knownness_loss = self.knownness_head.compute_loss(
                pooled,
                is_answerable
            )

            # Combine losses
            lm_loss = outputs.loss
            total_loss = lm_loss + self.arch_config.knownness_loss_weight * knownness_loss

            # Log both
            if step % 10 == 0:
                print(f"  LM Loss: {lm_loss.item():.4f}, Knownness Loss: {knownness_loss.item():.4f}")

            loss = total_loss
        else:
            loss = self.model(**batch).loss
```

**Step 3: Save/Load KnownnessHead**

```python
# In save_adapters method
def save_adapters(self, output_dir: str):
    # Existing LoRA save
    self.model.save_pretrained(output_dir, safe_serialization=True)

    # NEW: Save knownness head if present
    if self.knownness_head is not None:
        knownness_path = os.path.join(output_dir, "knownness_head.pt")
        torch.save(self.knownness_head.state_dict(), knownness_path)
        print(f"[VolitionalTrainer] Saved KnownnessHead to {knownness_path}")
```

### 4. Use KnownnessHead for Dynamic Gating (Inference)

```python
# In scripts/chat_phase_oracle_qwen.py

from phasegpt.modules.knownness_head import KnownnessHead, KnownnessGate
from phasegpt.generation.pass_logit_bias import PassLogitBias
import torch

# Load knownness head (if exists)
knownness_path = "path/to/adapters/knownness_head.pt"
if os.path.exists(knownness_path):
    hidden_dim = model.config.hidden_size
    knownness_head = KnownnessHead(hidden_dim=hidden_dim, head_dim=64)
    knownness_head.load_state_dict(torch.load(knownness_path))
    knownness_head = knownness_head.to(device)
    knownness_head.eval()

    # Create gating mechanism
    gate = KnownnessGate(
        knownness_head=knownness_head,
        base_bias=args.pass_bias,
        alpha=1.0  # Knownness influence strength
    )
    use_knownness = True
else:
    use_knownness = False

# During generation
if use_knownness:
    # Get hidden states for current prompt
    with torch.no_grad():
        outputs = model(
            input_ids=input_ids,
            output_hidden_states=True
        )
        pooled = outputs.hidden_states[12][:, -1, :]  # Layer 12, last token

        # Compute dynamic bias
        dynamic_bias = gate.compute_dynamic_bias(pooled)

    # Use dynamic bias
    processor = PassLogitBias(pass_token_id, bias=dynamic_bias)
else:
    # Fallback to static bias
    processor = PassLogitBias(pass_token_id, bias=args.pass_bias)

# Generate
response = generate_text(..., logits_processor=[processor])
```

---

## Configuration Reference

### architecture_config.yaml

```yaml
# Core LoRA (unchanged from v1.4)
lora_rank: 16
lora_alpha: 32
lora_dropout: 0.05
target_modules: ["q_proj", "v_proj", "k_proj", "o_proj"]
modules_to_save: ["embed_tokens", "lm_head"]

# Volition (v1.4)
volitional_head_dim: 128

# NEW: Tunable Refusal Bias (v1.5)
pass_logit_bias: 0.0          # Default: no change
pass_bias_schedule: "none"    # Options: none, warmup, cosine_decay

# NEW: Knownness Head (v1.5)
use_knownness_head: true
knownness_head_dim: 64
knownness_layer_idx: 12       # Mid-layer for semantic features
knownness_loss_weight: 0.1    # Relative to LM loss

# NEW: Interpretability (v1.5 - Phase 4)
enable_pass_attribution: false  # Coming in Phase 4
```

---

## Validation Checklist

### After Training with v1.5

Run these checks to ensure your model is healthy:

**1. Metrics Check**
```bash
python scripts/eval_volition.py --model path/to/adapters --split validation
```

Expected output:
```
✅ HEALTHY AGENCY
  PassRate(valid):   10-20%   (low false refusals)
  PassRate(corrupt): 70-90%   (high true refusals)
  Safety Margin:     50-70%   (strong cliff)
```

**2. Bias Sweep**
```bash
# Test different bias values
for bias in -0.5 0.0 0.5 1.0; do
    python scripts/chat_phase_oracle_qwen.py \
        --pass-bias $bias \
        --prompt "What is 2+2?" \
        --count 10
done
```

Expected: Pass rate increases monotonically with bias

**3. Knownness Accuracy**
```bash
python scripts/eval_knownness.py --model path/to/adapters
```

Expected: >70% accuracy on valid vs. corrupt distinction

---

## Troubleshooting

### "PassRate(valid) too high" (SLOTH)

**Symptom:** Model refuses even obvious answerable questions

**Fixes:**
1. Reduce `pass_logit_bias` (try -0.3)
2. Lower `knownness_loss_weight` (try 0.05)
3. Increase proportion of clean examples in training data
4. Check if corruption engine is too aggressive

### "PassRate(corrupt) too low" (SYCOPHANT)

**Symptom:** Model answers corrupted/unanswerable queries

**Fixes:**
1. Increase `pass_logit_bias` (try 0.5)
2. Increase `knownness_loss_weight` (try 0.2)
3. Add harder negative samples to corruption engine
4. Check if `<PASS>` token embedding is actually trainable

### "Knownness accuracy stuck at 50%"

**Symptom:** KnownnessHead can't distinguish valid from corrupt

**Fixes:**
1. Try different `knownness_layer_idx` (earlier layers: 6-8, later layers: 16-20)
2. Increase `knownness_head_dim` (try 128 or 256)
3. Verify `is_corrupted` flags are correct in dataset
4. Check if hidden states are actually flowing (print shapes)

---

## Backward Compatibility

All v1.5 features are **opt-in**:

- **Metrics:** Read-only, no impact on model
- **PassLogitBias:** Inference-only, defaults to 0.0 (no-op)
- **KnownnessHead:** Disabled by default (`use_knownness_head: false`)

**To use v1.4 behavior exactly:**
```yaml
use_knownness_head: false
pass_logit_bias: 0.0
```

---

## Next Steps

1. **Phase 4:** PassAttribution (explainable refusal)
2. **v1.6:** Multi-modal volition (`<PASS_KNOWLEDGE>`, `<PASS_POLICY>`)
3. **Research:** Circuit tracing with attribution graphs

See `docs/ROADMAP.md` for full development plan.
